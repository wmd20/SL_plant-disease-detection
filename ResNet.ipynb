{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "统计大作业",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8+Y1SlrsgJS6lEk2joZpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wmd20/SL_plant-disease-detection/blob/master/%E7%BB%9F%E8%AE%A1%E5%A4%A7%E4%BD%9C%E4%B8%9A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmZBkan79ySH",
        "outputId": "867bb6e3-c458-4744-b225-a77425348949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "! git clone https://github.com/wmd20/SL_plant-disease-detection.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SL_plant-disease-detection'...\n",
            "remote: Enumerating objects: 31581, done.\u001b[K\n",
            "remote: Total 31581 (delta 0), reused 0 (delta 0), pack-reused 31581\u001b[K\n",
            "Receiving objects: 100% (31581/31581), 2.81 GiB | 47.05 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Checking out files: 100% (31741/31741), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2h5V9o0BT8s",
        "outputId": "4a55f5a2-d8f3-4349-ba9b-bf9bff5f7249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "def readFile(path,flag):\n",
        "    image_dir=sorted(os.listdir(path))\n",
        "    x=np.zeros((len(image_dir),256,256,3),dtype=np.uint8)\n",
        "    y=np.zeros((len(image_dir)),dtype=np.uint8)\n",
        "    for i,file in enumerate(image_dir):\n",
        "        img=cv2.imread(os.path.join(path,file))\n",
        "        x[i,:,:]=cv2.resize(img,(256,256))\n",
        "        if flag:\n",
        "            y[i]=int(file.split(',')[0]) # label 的映射需要重新定义\n",
        "    if flag:\n",
        "        return x,y\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "# 分别将 training set,validation set,testing set 用readFile函数读进来\n",
        "workSpace_dir='SL_plant-disease-detection'\n",
        "print(\"Reading data...\")\n",
        "train_x,train_y=readFile(os.path.join(workSpace_dir,\"trainingset_part1\"),True)\n",
        "print(\"Size of training data={}\".format(len(train_x)))\n",
        "val_x,val_y=readFile(os.path.join(workSpace_dir,\"trainingset_part1\"),True)\n",
        "print(\"Size of validation data={}\".format(len(val_x)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data...\n",
            "Size of training data=2981\n",
            "Size of validation data=2981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYQEkmE-C5ox"
      },
      "source": [
        "#training 時做 data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(), #隨機將圖片水平翻轉\n",
        "    transforms.RandomRotation(15), #隨機旋轉圖片\n",
        "    transforms.ToTensor(), #將圖片轉成 Tensor，並把數值normalize到[0,1](data normalization)\n",
        "])\n",
        "#testing 時不需做 data augmentation\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                    \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, x, y=None, transform=None):\n",
        "        self.x = x\n",
        "        # label is required to be a LongTensor\n",
        "        self.y = y\n",
        "        if y is not None:\n",
        "            self.y = torch.LongTensor(y)\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, index):\n",
        "        X = self.x[index]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        if self.y is not None:\n",
        "            Y = self.y[index]\n",
        "            return X, Y\n",
        "        else:\n",
        "            return X\n",
        "batch_size=128\n",
        "train_set=ImgDataset(train_x,train_y,train_transform)\n",
        "val_set=ImgDataset(val_x,val_y,test_transform)\n",
        "train_loader=DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(val_set,batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzKU4RiY6z30",
        "outputId": "8cf92616-32ce-4bf2-92b9-0da55df8e068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class Residual_Block(nn.Module):\n",
        "    def __init__(self, i_channel, o_channel, stride, down_sample = None):\n",
        "        super(Residual_Block, self).__init__()\n",
        "        # 第一个卷积层，卷积块大小为 1 * 1\n",
        "        self.conv1 = nn.Conv2d(in_channels = i_channel,\n",
        "                    out_channels = o_channel,\n",
        "                    stride = stride,\n",
        "                    padding = 0,\n",
        "                    kernel_size = 1,\n",
        "                    bias = False)\n",
        "        # BatchNorm2d()对小批量3d数据组成的4d输入进行批标准化操作\n",
        "        # 主要为了防止神经网络退化\n",
        "        self.bn1 = nn.BatchNorm2d(o_channel)\n",
        "        # Relu\n",
        "        self.relu1 = nn.ReLU(inplace = True)\n",
        "        # 第二卷积层, 3 * 3 的卷积\n",
        "        self.conv2 = nn.Conv2d(in_channels = o_channel, \n",
        "                    out_channels = o_channel, \n",
        "                    kernel_size = 3, \n",
        "                    stride = 1, \n",
        "                    padding = 1,\n",
        "                    bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(o_channel)\n",
        "        # Relu\n",
        "        self.relu2 = nn.ReLU(inplace = True)\n",
        "        # 第三卷积层，1 * 1的卷积块，输出通道为 4 * 第一个卷积输出通道\n",
        "        self.conv3 = nn.Conv2d(in_channels = o_channel,\n",
        "                    out_channels = 4 * o_channel,\n",
        "                    kernel_size = 1,\n",
        "                    stride = 1,\n",
        "                    padding = 0,\n",
        "                    bias = False)\n",
        "        # bn\n",
        "        self.bn3 = nn.BatchNorm2d(4 * o_channel)\n",
        "        # relu\n",
        "        self.relu3 = nn.ReLU(inplace = True)\n",
        "        self.down_sample = down_sample\n",
        "        self.stride = stride\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        print('residual.shape = ' + str(residual.shape))\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        #print('第一层卷积结束后的尺寸' + str(out.shape))\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        #print('第二层卷积结束后的尺寸' + str(out.shape))\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        #print('out.shape = ' + str(out.shape))\n",
        "        if self.stride == 2:\n",
        "            down_sample = nn.Sequential(nn.Conv2d(residual.size(1),\n",
        "                                residual.size(1) * 2,\n",
        "                                kernel_size = 1,\n",
        "                                stride = 2,\n",
        "                                padding = 0,\n",
        "                                bias = False),\n",
        "                                nn.BatchNorm2d(residual.size(1) * 2))\n",
        "            residual = down_sample(residual)\n",
        "        #if self.down_sample:\n",
        "           # residual = self.down_sample(x) # 下采样\n",
        "        # 将单元的输入直接与单元输出加在一起\n",
        "        if residual.shape != out.shape:\n",
        "            residual = torch.cat((residual.cuda(), torch.zeros(x.size(0), out.size(1) - x.size(1), out.size(2), out.size(3).cuda())), 1).cuda()\n",
        "        #print('residual.size = ' + str(residual.shape)) \n",
        "        #print()\n",
        "        out += residual\n",
        "        out = self.relu3(out)\n",
        "        #print(out.shape)\n",
        "        return out\n",
        "    \n",
        "# 定义残差神经网络\n",
        "class ResNet50(nn.Module):\n",
        "    # 残差块、层数、类别数量\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet50, self).__init__()\n",
        "        # 第一层卷积， 输入3通道， 输出64通道， 7 * 7的卷积\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, \n",
        "                    out_channels = 64, \n",
        "                    kernel_size = 7,  \n",
        "                    stride = 2,\n",
        "                    padding = 0,\n",
        "                    bias = False)\n",
        "        # 标记输出通道，为后面输入输出相加时是否需要做维度变换提供判断，\n",
        "        self.in_channels = 64\n",
        "        # 归一化\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # Relu\n",
        "        self.relu1 = nn.ReLU(inplace = True)\n",
        "        # 最大池化，3*3的池化窗口，stride = 2\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        # 第一种残差块\n",
        "        self.block1 = Residual_Block(i_channel = 64, o_channel = 64, stride = 1)\n",
        "        self.block2 = Residual_Block(i_channel = 256, o_channel = 64, stride = 1)\n",
        "        self.block3 = Residual_Block(i_channel = 256, o_channel = 64, stride = 1)\n",
        "        \n",
        "        # 第二类残差块\n",
        "        self.block4 = Residual_Block(i_channel = 256, o_channel = 128, stride = 2)\n",
        "        self.block5 = Residual_Block(i_channel = 512, o_channel = 128, stride = 1)\n",
        "        self.block6 = Residual_Block(i_channel = 512, o_channel = 128, stride = 1)\n",
        "        self.block7 = Residual_Block(i_channel = 512, o_channel = 128, stride = 1)\n",
        "        \n",
        "        # 第三类残差块\n",
        "        self.block8 = Residual_Block(i_channel = 512, o_channel = 256, stride = 2)\n",
        "        self.block9 = Residual_Block(i_channel = 1024, o_channel = 256, stride = 1)\n",
        "        self.block10 = Residual_Block(i_channel = 1024, o_channel = 256, stride = 1)\n",
        "        self.block11 = Residual_Block(i_channel = 1024, o_channel = 256, stride = 1)\n",
        "        self.block12 = Residual_Block(i_channel = 1024, o_channel = 256, stride = 1)\n",
        "        self.block13 = Residual_Block(i_channel = 1024, o_channel = 256, stride = 1)\n",
        "        \n",
        "        # 第四类残差块\n",
        "        self.block14 = Residual_Block(i_channel = 1024, o_channel = 512, stride = 2)\n",
        "        self.block15 = Residual_Block(i_channel = 2048, o_channel = 512, stride = 1)\n",
        "        self.block16 = Residual_Block(i_channel = 2048, o_channel = 512, stride = 1)\n",
        "        # 平均池化层，窗口大小 8 * 8\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        # 全连接层\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "        # softmax层\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, x):\n",
        "      print('前向传播' + str(x.shape))\n",
        "      out = self.conv1(x)\n",
        "      print('第一层卷积' + str(out.shape))\n",
        "      out = self.bn1(out)\n",
        "      out = self.relu1(out)\n",
        "      #print('第一层卷积' + str(out.shape))\n",
        "      out = self.maxpool(out)\n",
        "      #print('最大池化后' + str(out.shape))\n",
        "      out = self.block1(out)\n",
        "      #print('block1后' + str(out.shape))\n",
        "      out = self.block2(out)\n",
        "      #print('block2后' + str(out.shape))\n",
        "      out = self.block3(out)\n",
        "      #print('第一残差块之后' + str(out.shape))\n",
        "      out = self.block4(out)\n",
        "      #print('block4后' + str(out.shape))\n",
        "      out = self.block5(out)\n",
        "      out = self.block6(out)\n",
        "      out = self.block7(out)\n",
        "      #print('第二类残差块之后：' + str(out.shape))\n",
        "      out = self.block8(out)\n",
        "      out = self.block9(out)\n",
        "      out = self.block10(out)\n",
        "      out = self.block11(out)\n",
        "      out = self.block12(out)\n",
        "      out = self.block13(out)\n",
        "      #print('第三类残差块之后' + str(out.shape))\n",
        "      out = self.block14(out)\n",
        "      out = self.block15(out)\n",
        "      out = self.block16(out)\n",
        "      #print('第四类残差块之后' + str(out.shape))\n",
        "      out = self.avg_pool(out)\n",
        "      #将四维张量转换为二维张量之后，才能作为全连接层的输入\n",
        "      out = out.view(out.size()[0], -1)\n",
        "      out = self.fc(out)\n",
        "      #print('全连接层输出' + str(out))\n",
        "      out = self.softmax(out)\n",
        "      return out\n",
        "    \n",
        "#更新学习率\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "        \n",
        "# 固定随机种子\n",
        "random.seed(1)\n",
        "# 超参数设定\n",
        "batch_size = 16\n",
        "learning_rate = 1e-3\n",
        "# 定义模型\n",
        "model = ResNet50(8).cuda()\n",
        "# 因为是分类任务，所以使用交叉熵损失 \n",
        "loss=nn.CrossEntropyLoss() # 因为是 classification task,所以loss使用crossEntropyLoss\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "num_epoch=30\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time=time.time()\n",
        "    train_acc=0.0\n",
        "    train_loss=0.0\n",
        "    val_acc=0.0\n",
        "    val_loss=0.0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for i,data in enumerate(train_loader):\n",
        "      print('data[0].shape' + str(data[0].shape))\n",
        "      optimizer.zero_grad() # 用optimizer 将model参数的gradient归零\n",
        "      train_pred=model(data[0].cuda()) #利用model得到预测的概率分布，这边实际上就是去call model的froward 函数\n",
        "      batch_loss=loss(train_pred,data[1].cuda()) #计算loss 注意 prediction跟label必须同时待在CPU或是GPU上\n",
        "      batch_loss.backward() # 利用back probagation 算出每个参数的gradient\n",
        "      optimizer.step() #更新参数\n",
        "      \n",
        "      train_acc+=np.sum(np.argmax(train_pred.data.numpy(),axis=1)==data[1].numpy())\n",
        "      train_loss+=batch_loss.item()\n",
        "        \n",
        "    model.eval()\n",
        "    with torch.no_grad(): # torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度\n",
        "        for i,data in enumerate(val_loader):\n",
        "          val_pred=model(data[0].cuda())\n",
        "          batch_loss=loss(val_pred,data[1].cuda())\n",
        "          \n",
        "          val_acc+=np.sum(np.argmax(val_pred.data.numpy(),axis=1)==data[1].numpy)\n",
        "          val_loss+=batch_loss.item()\n",
        "        #将结果 print 出来\n",
        "        print('[%03d/%03d] %2.2f sec(s) Trian Acc:%3.6f Loss:%3.6f | Val Acc:%3.6f Loss:%3.6f' %\\\n",
        "             (epoch+1,num_epoch,time.time()-epoch_start_time,\\\n",
        "             train_acc/train_set.__len__(),train_loss/train_set.__len__(),\\\n",
        "             val_acc/val_set.__len__(),val_loss/val_set.__len__()))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data[0].shapetorch.Size([128, 3, 256, 256])\n",
            "前向传播torch.Size([128, 3, 256, 256])\n",
            "第一层卷积torch.Size([128, 64, 125, 125])\n",
            "residual.shape = torch.Size([128, 64, 62, 62])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-46ae288e0008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data[0].shape'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 用optimizer 将model参数的gradient归零\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m       \u001b[0mtrain_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#利用model得到预测的概率分布，这边实际上就是去call model的froward 函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0mbatch_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#计算loss 注意 prediction跟label必须同时待在CPU或是GPU上\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 利用back probagation 算出每个参数的gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-46ae288e0008>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;31m#print('最大池化后' + str(out.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m       \u001b[0;31m#print('block1后' + str(out.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-46ae288e0008>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# 将单元的输入直接与单元输出加在一起\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m#print('residual.size = ' + str(residual.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#print()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'cuda'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krzhSPnO9oW8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
